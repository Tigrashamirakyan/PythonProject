import streamlit as st
from process import (
    extract_text_from_file,
    split_text,
    vectorize_chunks,
    split_json_if_large,
    send_to_webhook
)

st.title("üîç –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ —Ñ–∞–π–ª–æ–≤")

st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é.")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
uploaded_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã (TXT, PDF, DOCX, CSV)", accept_multiple_files=True)

# –†—É—á–Ω–æ–π –≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
manual_text = st.text_area("–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é", "")

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
model_choice = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏", ["openai", "yandex", "sentence_transformer"])

# –í–≤–æ–¥ Webhook URL
webhook_url = st.text_input("Webhook URL", "https://example.com/webhook")

# –°–ª–∞–π–¥–µ—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (–æ—Ç 1 –¥–æ 10 –ú–ë)
size_threshold_mb = st.slider("–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (–ú–ë)", 1, 10, 1)
max_size_bytes = size_threshold_mb * 1024 * 1024

if st.button("üß† –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
    full_text = ""
    # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Ñ–∞–π–ª—ã ‚Äì –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö
    if uploaded_files:
        for file in uploaded_files:
            text = extract_text_from_file(file)
            if text:
                ext = file.name.lower().split('.')[-1]
                file_type = ext if ext in ["pdf", "docx"] else None
                chunks = split_text(text, file_type=file_type)
                full_text += "\n".join(chunks) + "\n"
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–≤–µ–¥—ë–Ω–Ω—ã–π –≤—Ä—É—á–Ω—É—é —Ç–µ–∫—Å—Ç
    if manual_text:
        full_text += manual_text

    if not full_text.strip():
        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏!")
    else:
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
        chunks = split_text(full_text)
        st.write(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤")
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
        vectors = vectorize_chunks(chunks, model_choice)
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π JSON
        json_data = {
            "status": "success",
            "model": model_choice,
            "original_text": full_text,
            "chunks": [
                {"chunk_id": i + 1, "text": chunk, "vector": vector}
                for i, (chunk, vector) in enumerate(zip(chunks, vectors))
            ]
        }
        # –ï—Å–ª–∏ JSON –±–æ–ª—å—à–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ ‚Äì —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
        files_data = split_json_if_large(json_data, max_size_bytes)
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π Webhook
        for idx, data_part in enumerate(files_data):
            status_code, response_text = send_to_webhook(webhook_url, data_part)
            st.write(f"–ß–∞—Å—Ç—å {idx + 1} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞, —Å—Ç–∞—Ç—É—Å: {status_code}")
        st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É!")
